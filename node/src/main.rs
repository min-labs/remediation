// M13 NODE — Orchestrator

mod engine;
mod cryptography;
mod network;

use crate::engine::protocol::*;
use crate::engine::protocol::{Assembler, FragHeader, FRAG_HDR_SIZE, send_fragmented_udp};
use crate::engine::runtime::{
    rdtsc_ns, calibrate_tsc,
    fatal, NodeState, HexdumpState};
use crate::cryptography::aead::{seal_frame, open_frame};
use crate::network::datapath::{create_tun, setup_tunnel_routes, teardown_tunnel_routes, nuke_cleanup};
use crate::cryptography::handshake::{initiate_handshake, process_handshake_node};

use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Mutex;
use std::net::UdpSocket;
use std::os::unix::io::AsRawFd;

use ring::aead;

static SHUTDOWN: AtomicBool = AtomicBool::new(false);
extern "C" fn signal_handler(_sig: i32) { SHUTDOWN.store(true, Ordering::Relaxed); }

/// Global Hub IP for panic hook cleanup. Set once before worker starts.
static HUB_IP_GLOBAL: Mutex<String> = Mutex::new(String::new());

/// Nuclear cleanup: tear down EVERYTHING — routes, TUN, IPv6, iptables.
/// Safe to call multiple times (idempotent). Safe to call from panic hook.
fn nuke_cleanup_node() {
    nuke_cleanup(&HUB_IP_GLOBAL);
}

// ── MAIN ───────────────────────────────────────────────────────────────────
fn main() {
    // Logs go to terminal (stderr)

    let args: Vec<String> = std::env::args().collect();
    // SAFETY: Caller ensures invariants documented at module level.
    unsafe {
        libc::signal(libc::SIGTERM, signal_handler as *const () as libc::sighandler_t);
        libc::signal(libc::SIGINT, signal_handler as *const () as libc::sighandler_t);
    }

    // Panic hook: guarantee cleanup even on unwinding crash
    std::panic::set_hook(Box::new(|info| {
        eprintln!("[M13-NODE] PANIC: {}", info);
        nuke_cleanup_node();
        std::process::exit(1);
    }));

    let echo = args.iter().any(|a| a == "--echo");
    let hexdump = args.iter().any(|a| a == "--hexdump");
    let tunnel = args.iter().any(|a| a == "--tunnel");

    // Create TUN interface if requested
    // Note: MUST be done before dropping privileges (if any)
    let tun_file = if tunnel {
        Some(create_tun("m13tun0").expect("Failed to create TUN interface"))
    } else {
        None
    };

    // Parse --hub-ip <ip:port> (required)
    let mut hub_ip = None;
    let mut i = 1;
    while i < args.len() {
        if args[i] == "--hub-ip" && i + 1 < args.len() {
            hub_ip = Some(args[i+1].clone());
        }
        i += 1;
    }

    if let Some(ip) = hub_ip {
        // Store Hub IP globally so panic hook can tear down routes
        if let Ok(mut g) = HUB_IP_GLOBAL.lock() {
            *g = ip.split(':').next().unwrap_or(&ip).to_string();
        }
        run_udp_worker(&ip, echo, hexdump, tun_file);
    } else {
         eprintln!("Usage: m13-node --hub-ip <ip:port> [--echo] [--hexdump] [--tunnel]");
         std::process::exit(1);
    }

    // Post-worker cleanup: nuke everything
    nuke_cleanup_node();
}

// ── Shared RX Processing ────────────────────────────────────────────────
use std::io::{Read, Write};

/// What the transport-specific caller should do after shared RX processing.
enum RxAction {
    /// Drop the frame (invalid, failed AEAD, or consumed internally).
    Drop,
    /// Tunnel data: write payload at (start, len) to TUN device.
    TunWrite { start: usize, plen: usize },
    /// Echo: caller should build echo response using the frame.
    Echo,
    /// Handshake complete: send Finished payload, transition to Established.
    HandshakeComplete { session_key: [u8; 32], finished_payload: Vec<u8> },
    /// Handshake failed: transition to Disconnected.
    HandshakeFailed,
    /// Rekey needed: transition to Registering.
    RekeyNeeded,
    /// Registration trigger: caller should initiate handshake.
    NeedHandshakeInit,
}

/// Shared RX frame processing for both UDP and AF_XDP workers.
/// Handles: M13 validation, AEAD decrypt, rekey, flag re-read,
/// fragment reassembly, handshake processing, classify.
///
/// The frame must include the ETH header at offset 0 and M13 at ETH_HDR_SIZE.
/// For UDP, the outer UDP/IP headers are stripped before calling this.
fn process_rx_frame(
    buf: &mut [u8],
    state: &mut NodeState,
    assembler: &mut Assembler,
    _hexdump: &mut HexdumpState,
    now: u64,
    echo: bool,
    aead_fail_count: &mut u64,
) -> RxAction {
    let len = buf.len();

    if len < ETH_HDR_SIZE + M13_HDR_SIZE {
        return RxAction::Drop;
    }

    // SAFETY: Pointer arithmetic within UMEM bounds; offset validated by kernel ring descriptor.
    let m13 = unsafe { &*(buf.as_ptr().add(ETH_HDR_SIZE) as *const M13Header) };
    if m13.signature[0] != M13_WIRE_MAGIC || m13.signature[1] != M13_WIRE_VERSION {
        return RxAction::Drop;
    }

    // Registration trigger: initiate handshake on first valid Hub frame
    if matches!(state, NodeState::Registering) {
        return RxAction::NeedHandshakeInit;
    }

    // Initial flags (may be ciphertext — will re-read after decrypt)
    let _flags_pre = m13.flags;

    // Pre-decrypted by batch AEAD — skip both decrypt and cleartext-reject.
    // PRE_DECRYPTED_MARKER (0x02) is stamped by decrypt_batch_ptrs on success.
    let pre_decrypted = buf[ETH_HDR_SIZE + 2] == crate::cryptography::aead::PRE_DECRYPTED_MARKER;

    if !pre_decrypted {
        // Mandatory encryption — reject cleartext data after session
        // Exempt: handshakes, fragments, and control frames (FIN/keepalive)
        if matches!(state, NodeState::Established { .. })
           && buf[ETH_HDR_SIZE + 2] != 0x01
           && _flags_pre & FLAG_HANDSHAKE == 0 && _flags_pre & FLAG_FRAGMENT == 0
           && _flags_pre & FLAG_CONTROL == 0 {
            return RxAction::Drop; // drop cleartext data frame
        }

        // AEAD verification on encrypted frames (scalar fallback for non-batched frames)
        if buf[ETH_HDR_SIZE + 2] == 0x01 {
            if let NodeState::Established { ref cipher, ref mut frame_count, ref established_ns, .. } = state {
                if !open_frame(buf, cipher, DIR_NODE_TO_HUB) {
                    *aead_fail_count += 1;
                    if cfg!(debug_assertions) && *aead_fail_count <= 3 {
                        eprintln!("[M13-NODE-AEAD] FAIL #{} len={} nonce={:02x}{:02x}{:02x}{:02x}{:02x}{:02x}{:02x}{:02x}:{:02x}{:02x}{:02x}{:02x}",
                            aead_fail_count, len,
                            buf[ETH_HDR_SIZE+20], buf[ETH_HDR_SIZE+21], buf[ETH_HDR_SIZE+22], buf[ETH_HDR_SIZE+23],
                            buf[ETH_HDR_SIZE+24], buf[ETH_HDR_SIZE+25], buf[ETH_HDR_SIZE+26], buf[ETH_HDR_SIZE+27],
                            buf[ETH_HDR_SIZE+28], buf[ETH_HDR_SIZE+29], buf[ETH_HDR_SIZE+30], buf[ETH_HDR_SIZE+31]);
                    }
                    return RxAction::Drop;
                }
                *frame_count += 1;

                // Rekey check — frame count or time limit
                if *frame_count >= REKEY_FRAME_LIMIT
                   || now.saturating_sub(*established_ns) > REKEY_TIME_LIMIT_NS {
                    eprintln!("[M13-NODE-PQC] Rekey threshold reached. Re-initiating handshake.");
                    return RxAction::RekeyNeeded;
                }
            } else {
                return RxAction::Drop; // encrypted frame but no session
            }
        }
    }
    // pre_decrypted frames: batch decrypt already verified AEAD, incremented
    // frame_count, and checked rekey. Proceed directly to flag re-read + classify.

    // CRITICAL: Re-read flags from decrypted buffer.
    // Original flags were read BEFORE decrypt — they hold ciphertext.
    let flags = buf[ETH_HDR_SIZE + 40];

    // Fragment handling
    if flags & FLAG_FRAGMENT != 0 && len >= ETH_HDR_SIZE + M13_HDR_SIZE + FRAG_HDR_SIZE {
        // SAFETY: Pointer arithmetic within valid bounds.
        let frag_hdr = unsafe { &*(buf.as_ptr().add(ETH_HDR_SIZE + M13_HDR_SIZE) as *const FragHeader) };
        // SAFETY: Using read_unaligned because FragHeader is repr(C, packed).
        let frag_msg_id = unsafe { std::ptr::addr_of!(frag_hdr.frag_msg_id).read_unaligned() };
        let frag_index = unsafe { std::ptr::addr_of!(frag_hdr.frag_index).read_unaligned() };
        let frag_total = unsafe { std::ptr::addr_of!(frag_hdr.frag_total).read_unaligned() };
        let frag_offset = unsafe { std::ptr::addr_of!(frag_hdr.frag_offset).read_unaligned() };
        let frag_data_len = unsafe { std::ptr::addr_of!(frag_hdr.frag_len).read_unaligned() } as usize;
        let frag_start = ETH_HDR_SIZE + M13_HDR_SIZE + FRAG_HDR_SIZE;
        if frag_start + frag_data_len <= len {
            if let Some(reassembled) = assembler.feed(
                frag_msg_id, frag_index, frag_total, frag_offset,
                &buf[frag_start..frag_start + frag_data_len], now,
            ) {
                if flags & FLAG_HANDSHAKE != 0 {
                    eprintln!("[M13-NODE] Reassembled handshake msg_id={} len={}",
                        frag_msg_id, reassembled.len());
                    if let Some((session_key, finished_payload)) = process_handshake_node(&reassembled, state) {
                        return RxAction::HandshakeComplete { session_key, finished_payload };
                    } else {
                        return RxAction::HandshakeFailed;
                    }
                } else {
                    if cfg!(debug_assertions) {
                        eprintln!("[M13-NODE] Reassembled data msg_id={} len={}",
                            frag_msg_id, reassembled.len());
                    }
                }
            }
        }
        return RxAction::Drop; // Fragment consumed (or partial)
    }

    // Control frame — consume
    if flags & FLAG_CONTROL != 0 {
        return RxAction::Drop;
    }

    // Tunnel data → TUN write
    if flags & FLAG_TUNNEL != 0 {
        let start = ETH_HDR_SIZE + M13_HDR_SIZE;
        let plen_bytes = &buf[55..59];
        let plen = u32::from_le_bytes(plen_bytes.try_into().unwrap()) as usize;
        if start + plen <= len {
            return RxAction::TunWrite { start, plen };
        }
        return RxAction::Drop;
    }

    // Echo
    if echo && matches!(state, NodeState::Established { .. }) {
        return RxAction::Echo;
    }

    RxAction::Drop
}

/// Read a sysctl value from /proc/sys (e.g. "net.core.rmem_max" → "/proc/sys/net/core/rmem_max").
fn read_sysctl(key: &str) -> Option<String> {
    let path = format!("/proc/sys/{}", key.replace('.', "/"));
    std::fs::read_to_string(&path).ok().map(|s| s.trim().to_string())
}

/// Apply a sysctl and verify it took effect. Returns true if verified.
fn apply_sysctl(key: &str, value: &str) -> bool {
    let arg = format!("{}={}", key, value);
    let _ = std::process::Command::new("sysctl").args(["-w", &arg]).output();
    // Read back to verify
    match read_sysctl(key) {
        Some(actual) => actual == value,
        None => false,
    }
}

/// Pre-flight system tuning — applied once per startup (requires root).
/// Symmetric counterpart: Hub does the same in `setup_nat()`.
fn tune_system_buffers() {
    eprintln!("[M13-TUNE] Applying kernel + NIC tuning...");
    let mut ok = 0u32;
    let mut fail = 0u32;

    // 1. WiFi power save off — eliminates 20-100ms wake latency on RX.
    //    Auto-detect wireless interface from /sys/class/net/*/wireless.
    if let Ok(entries) = std::fs::read_dir("/sys/class/net") {
        for entry in entries.flatten() {
            let name = entry.file_name();
            let iface = name.to_string_lossy().to_string();
            let wireless_path = format!("/sys/class/net/{}/wireless", iface);
            if std::path::Path::new(&wireless_path).exists() {
                let r = std::process::Command::new("iw")
                    .args(["dev", &iface, "set", "power_save", "off"]).output();
                if r.map(|o| o.status.success()).unwrap_or(false) {
                    eprintln!("[M13-TUNE] WiFi power_save OFF on {}", iface);
                    ok += 1;
                } else {
                    eprintln!("[M13-TUNE] WARN: WiFi power_save off failed on {}", iface);
                    fail += 1;
                }
            }
        }
    }

    // 2. Socket buffer ceiling
    for (k, v) in [
        ("net.core.rmem_max", "8388608"), ("net.core.wmem_max", "8388608"),
        ("net.core.rmem_default", "4194304"), ("net.core.wmem_default", "4194304"),
    ] { if apply_sysctl(k, v) { ok += 1; } else { fail += 1; eprintln!("[M13-TUNE] WARN: {} failed", k); } }

    // 3. NAPI budget
    for (k, v) in [("net.core.netdev_budget", "600"), ("net.core.netdev_budget_usecs", "8000")] {
        if apply_sysctl(k, v) { ok += 1; } else { fail += 1; eprintln!("[M13-TUNE] WARN: {} failed", k); }
    }

    // 4. Backlog queue
    if apply_sysctl("net.core.netdev_max_backlog", "10000") { ok += 1; } else { fail += 1; }

    // 5. BBR congestion control
    if apply_sysctl("net.ipv4.tcp_congestion_control", "bbr") { ok += 1; } else { fail += 1; eprintln!("[M13-TUNE] WARN: BBR not available"); }

    // 6. Don't cache stale TCP metrics
    if apply_sysctl("net.ipv4.tcp_no_metrics_save", "1") { ok += 1; } else { fail += 1; }

    // 7. MTU probing (mode 1 = probe on black hole detection)
    if apply_sysctl("net.ipv4.tcp_mtu_probing", "1") { ok += 1; } else { fail += 1; }

    if fail == 0 {
        eprintln!("[M13-TUNE] ✓ Optimisation Applied ({} sysctls verified)", ok);
    } else {
        eprintln!("[M13-TUNE] ⚠ Optimisation Partial ({}/{} applied, {} failed)", ok, ok + fail, fail);
    }
}

fn run_udp_worker(hub_addr: &str, echo: bool, hexdump_mode: bool, mut tun: Option<std::fs::File>) {
    let cal = calibrate_tsc();

    // ── Pre-flight: kernel + NIC tuning (before socket creation) ─────────
    tune_system_buffers();

    let sock = UdpSocket::bind("0.0.0.0:0")
        .unwrap_or_else(|_| fatal(0x30, "UDP bind failed"));
    sock.connect(hub_addr)
        .unwrap_or_else(|_| fatal(0x31, "UDP connect failed"));
    // O_NONBLOCK for recvmmsg busy-drain
    // Preserve existing flags (F_GETFL) then OR in O_NONBLOCK — never clobber.
    let raw_fd = sock.as_raw_fd();
    // SAFETY: Caller ensures invariants documented at module level.
    unsafe {
        let flags = libc::fcntl(raw_fd, libc::F_GETFL);
        libc::fcntl(raw_fd, libc::F_SETFL, flags | libc::O_NONBLOCK);

        // Socket buffer tuning — prevent burst drops.
        // Hub sends via AF_XDP at wire speed (bursts of 64+ packets per tick).
        // Default SO_RCVBUF (~208KB) overflows → silent UDP drops → TCP loss
        // → cwnd collapse → stall → slow start → "ticking" behavior.
        // 8MB absorbs ~5400 packets of burst at 1500B each.
        // SO_RCVBUFFORCE bypasses net.core.rmem_max (requires CAP_NET_ADMIN / root).
        let buf_sz: libc::c_int = 8 * 1024 * 1024; // 8MB
        libc::setsockopt(
            raw_fd, libc::SOL_SOCKET, libc::SO_RCVBUFFORCE,
            &buf_sz as *const _ as *const libc::c_void,
            std::mem::size_of::<libc::c_int>() as libc::socklen_t,
        );
        libc::setsockopt(
            raw_fd, libc::SOL_SOCKET, libc::SO_SNDBUFFORCE,
            &buf_sz as *const _ as *const libc::c_void,
            std::mem::size_of::<libc::c_int>() as libc::socklen_t,
        );
    }

    // Extract Hub IP (without port) for routing
    let hub_ip = hub_addr.split(':').next().unwrap_or(hub_addr).to_string();

    let mut seq_tx: u64 = 0;
    let mut rx_count: u64 = 0;
    let mut tx_count: u64 = 0;
    let mut aead_fail_count: u64 = 0;
    let mut aead_ok_count: u64 = 0;
    let mut tun_read_count: u64 = 0;
    let mut tun_write_count: u64 = 0;

    let mut hexdump = HexdumpState::new(hexdump_mode);
    let mut assembler = Assembler::new();

    let mut last_report_ns: u64 = rdtsc_ns(&cal);
    let mut last_keepalive_ns: u64 = 0;
    let mut gc_counter: u64 = 0;
    let mut routes_installed = false;
    let start_ns = rdtsc_ns(&cal); // For connection timeout

    let src_mac: [u8; 6] = detect_mac(None); // No local NIC in UDP mode
    let hub_mac: [u8; 6] = [0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF]; // broadcast — Hub identifies by addr

    eprintln!("[M13-NODE-UDP] Connected to {}. Echo={} Hexdump={}", hub_addr, echo, hexdump_mode);

    // Registration: send first frame to establish return path
    let reg = build_m13_frame(&src_mac, &hub_mac, seq_tx, FLAG_CONTROL);
    seq_tx += 1;
    if sock.send(&reg).is_ok() { tx_count += 1; }
    hexdump.dump_tx(&reg, rdtsc_ns(&cal));
    let mut state = NodeState::Registering;

    // 128KB rx_bufs + iovecs + mmsghdr — init once, not per-tick (cache thrashing prevention)
    const RX_BATCH: usize = 64;
    let mut rx_bufs: [[u8; 2048]; RX_BATCH] = [[0u8; 2048]; RX_BATCH];
    // SAFETY: Type is repr(C) and all-zeroes is a valid bit pattern.
    let mut rx_iovecs: [libc::iovec; RX_BATCH] = unsafe { std::mem::zeroed() };
    let mut rx_msgs: [libc::mmsghdr; RX_BATCH] = unsafe { std::mem::zeroed() };
    for i in 0..RX_BATCH {
        rx_iovecs[i].iov_base = rx_bufs[i].as_mut_ptr() as *mut libc::c_void;
        rx_iovecs[i].iov_len = 2048;
        rx_msgs[i].msg_hdr.msg_iov = &mut rx_iovecs[i] as *mut libc::iovec;
        rx_msgs[i].msg_hdr.msg_iovlen = 1;
    }

    // 100KB tx_bufs + iovecs + mmsghdr — init once (sendmmsg batch flush buffers)
    const TUN_BATCH: usize = 64;
    let mut tx_bufs: [[u8; 1600]; TUN_BATCH] = [[0u8; 1600]; TUN_BATCH];
    let mut tx_lens: [usize; TUN_BATCH] = [0; TUN_BATCH];
    // SAFETY: Type is repr(C) and all-zeroes is a valid bit pattern.
    let mut tx_iovecs: [libc::iovec; TUN_BATCH] = unsafe { std::mem::zeroed() };
    let mut tx_msgs: [libc::mmsghdr; TUN_BATCH] = unsafe { std::mem::zeroed() };

    // Avoids per-packet fill(0) of 30-byte signature region + 6 field writes.
    let mut hdr_template = [0u8; 62];
    hdr_template[0..6].copy_from_slice(&hub_mac);
    hdr_template[6..12].copy_from_slice(&src_mac);
    hdr_template[12] = (ETH_P_M13 >> 8) as u8;
    hdr_template[13] = (ETH_P_M13 & 0xFF) as u8;
    hdr_template[14] = M13_WIRE_MAGIC;
    hdr_template[15] = M13_WIRE_VERSION;
    // bytes 16..62 already 0 from array init

    // Gather-defer-flush: collect (rx_index, start, len) during RX classify,
    // flush all TUN writes in a tight sequential loop AFTER classify completes.
    // Eliminates syscall/classify interleaving — keeps L1d cache hot.
    const TUN_WR_BATCH: usize = 64; // matches RX_BATCH
    let mut tun_wr_indices: [u8; TUN_WR_BATCH] = [0; TUN_WR_BATCH];
    let mut tun_wr_starts: [u16; TUN_WR_BATCH] = [0; TUN_WR_BATCH];
    let mut tun_wr_lens: [u16; TUN_WR_BATCH] = [0; TUN_WR_BATCH];

    loop {
        if SHUTDOWN.load(Ordering::Relaxed) { break; }
        let now = rdtsc_ns(&cal);

        // Connection timeout (30s) if not established
        if !matches!(state, NodeState::Established { .. })
            && now.saturating_sub(start_ns) > 30_000_000_000 {
                eprintln!("[M13-NODE-UDP] Connection timed out (30s). Exiting.");
                break;
            }

        // Arrays pre-allocated outside loop — no per-tick memset (cache-friendly).
        // SAFETY: Caller ensures invariants documented at module level.
        let rx_n = unsafe {
            libc::recvmmsg(raw_fd, rx_msgs.as_mut_ptr(), RX_BATCH as u32,
                           libc::MSG_DONTWAIT, std::ptr::null_mut())
        };
        let rx_batch_count = if rx_n > 0 { rx_n as usize } else { 0 };
        let mut tun_wr_count: usize = 0; // reset per tick

        // Phase 1: Vectorized AEAD batch decrypt pre-pass
        // Identify encrypted frames, batch-decrypt with 4-at-a-time AES-NI/ARMv8-CE prefetch.
        // decrypt_one stamps PRE_DECRYPTED_MARKER (0x02) on success — process_rx_frame
        // recognizes it and skips both decrypt and cleartext-reject.
        if rx_batch_count > 0 {
            if let NodeState::Established { ref cipher, ref mut frame_count, ref established_ns, .. } = state {
                // Stack-allocated: zero heap allocation on hot path
                let mut enc_ptrs: [*mut u8; RX_BATCH] = [std::ptr::null_mut(); RX_BATCH];
                let mut enc_lens: [usize; RX_BATCH] = [0; RX_BATCH];
                let mut enc_count: usize = 0;
                for rx_i in 0..rx_batch_count {
                    let len = rx_msgs[rx_i].msg_len as usize;
                    if len >= ETH_HDR_SIZE + 40 && rx_bufs[rx_i][ETH_HDR_SIZE + 2] == 0x01 {
                        enc_ptrs[enc_count] = rx_bufs[rx_i].as_mut_ptr();
                        enc_lens[enc_count] = len;
                        enc_count += 1;
                    }
                }

                if enc_count > 0 {
                    let mut decrypt_results = [false; RX_BATCH];
                    let ok = crate::cryptography::aead::decrypt_batch_ptrs(
                        &enc_ptrs, &enc_lens, enc_count, cipher, DIR_NODE_TO_HUB,
                        &mut decrypt_results[..enc_count],
                    );
                    // decrypt_one stamps PRE_DECRYPTED_MARKER on successes automatically.
                    // Failures keep 0x01 → process_rx_frame scalar fallback.
                    *frame_count += ok as u64;
                    aead_ok_count += ok as u64;

                    // Rekey check after batch
                    if *frame_count >= REKEY_FRAME_LIMIT
                       || now.saturating_sub(*established_ns) > REKEY_TIME_LIMIT_NS {
                        eprintln!("[M13-NODE-PQC] Rekey threshold reached (batch). Re-initiating handshake.");
                        state = NodeState::Registering;
                    }
                }
            }
        }

        for rx_i in 0..rx_batch_count {
            let len = rx_msgs[rx_i].msg_len as usize;
            let buf = &mut rx_bufs[rx_i][..len];
            rx_count += 1;

            hexdump.dump_rx(buf, now);

            // Disconnected → Registering on any valid frame
            if matches!(state, NodeState::Disconnected) {
                state = NodeState::Registering;
            }

            let action = process_rx_frame(buf, &mut state, &mut assembler,
                &mut hexdump, now, echo, &mut aead_fail_count);

            match action {
                RxAction::NeedHandshakeInit => {
                    state = initiate_handshake(
                        &sock, &src_mac, &hub_mac, &mut seq_tx, &mut hexdump, &cal,
                    );
                    if cfg!(debug_assertions) { eprintln!("[M13-NODE-UDP] → Handshaking (PQC ClientHello sent)"); }
                }
                RxAction::TunWrite { start, plen } => {
                    if tun.is_some() && tun_wr_count < TUN_WR_BATCH {
                        tun_wr_indices[tun_wr_count] = rx_i as u8;
                        tun_wr_starts[tun_wr_count] = start as u16;
                        tun_wr_lens[tun_wr_count] = plen as u16;
                        tun_wr_count += 1;
                        tun_write_count += 1;
                    }
                }
                RxAction::Echo => {
                    if let Some(mut echo_frame) = build_echo_frame(buf, seq_tx) {
                        if let NodeState::Established { ref cipher, ref session_key, .. } = state {
                            if *session_key != [0u8; 32] {
                                seal_frame(&mut echo_frame, cipher, seq_tx, DIR_NODE_TO_HUB);
                            }
                        }
                        seq_tx += 1;
                        hexdump.dump_tx(&echo_frame, now);
                        if sock.send(&echo_frame).is_ok() { tx_count += 1; }
                    }
                }
                RxAction::HandshakeComplete { session_key, finished_payload } => {
                    let hs_flags = FLAG_CONTROL | FLAG_HANDSHAKE;
                    let frags = send_fragmented_udp(
                        &sock, &src_mac, &hub_mac,
                        &finished_payload, hs_flags,
                        &mut seq_tx, &mut hexdump, &cal,
                    );
                    if cfg!(debug_assertions) {
                        eprintln!("[M13-NODE-PQC] Finished sent: {}B, {} fragments",
                            finished_payload.len(), frags);
                    }

                    state = NodeState::Established {
                        session_key,
                        cipher: Box::new(aead::LessSafeKey::new(
                            aead::UnboundKey::new(&aead::AES_256_GCM, &session_key).unwrap()
                        )),
                        frame_count: 0,
                        established_ns: now,
                    };
                    if cfg!(debug_assertions) { eprintln!("[M13-NODE-PQC] → Established (session key derived, AEAD active)"); }

                    if tun.is_some() && !routes_installed {
                        setup_tunnel_routes(&hub_ip);
                        routes_installed = true;
                    }
                }
                RxAction::HandshakeFailed => {
                    eprintln!("[M13-NODE-PQC] Handshake processing failed → Disconnected");
                    state = NodeState::Disconnected;
                }
                RxAction::RekeyNeeded => {
                    state = NodeState::Registering;
                }
                RxAction::Drop => {} // consumed or invalid
            }
        }

        // All tunnel packets collected during classify are written here.
        // Tight sequential loop — cache-friendly, branch-predictor-friendly.
        if tun_wr_count > 0 {
            if let Some(ref mut tun_file) = tun {
                for ti in 0..tun_wr_count {
                    let ri = tun_wr_indices[ti] as usize;
                    let s = tun_wr_starts[ti] as usize;
                    let l = tun_wr_lens[ti] as usize;
                    let _ = tun_file.write(&rx_bufs[ri][s..s + l]);
                }
            }
        }

        if let NodeState::Handshaking { started_ns, .. } = &state {
            if now.saturating_sub(*started_ns) > HANDSHAKE_TIMEOUT_NS {
                eprintln!("[M13-NODE-PQC] Handshake timeout ({}s). Retrying...",
                    HANDSHAKE_TIMEOUT_NS / 1_000_000_000);
                // Recovery: re-send registration and go back to Registering
                let reg = build_m13_frame(&src_mac, &hub_mac, seq_tx, FLAG_CONTROL);
                seq_tx += 1;
                if sock.send(&reg).is_ok() { tx_count += 1; }
                state = NodeState::Registering;
                assembler = Assembler::new(); // Clear stale fragments
            }
        }

        // === Keepalive — only during registration/handshake (100ms) ===
        // Once Established, TUN data traffic maintains NAT hole naturally.
        // Keepalives STOP when session is up.
        if !matches!(state, NodeState::Established { .. })
            && (now.saturating_sub(last_keepalive_ns) > 100_000_000 || tx_count == 0) {
                last_keepalive_ns = now;
                let ka = build_m13_frame(&src_mac, &hub_mac, seq_tx, FLAG_CONTROL);
                seq_tx += 1;
                if sock.send(&ka).is_ok() { tx_count += 1; }
            }

        // === Telemetry: report every second ===
        if now.saturating_sub(last_report_ns) > 1_000_000_000 {
            let state_label = match &state {
                NodeState::Registering => "Reg",
                NodeState::Handshaking { .. } => "HS",
                NodeState::Established { .. } => "Est",
                NodeState::Disconnected => "Disc",
            };
            eprintln!("[M13-N0] RX:{} TX:{} TUN_R:{} TUN_W:{} AEAD_OK:{} FAIL:{} State:{}",
                rx_count, tx_count, tun_read_count, tun_write_count, aead_ok_count, aead_fail_count, state_label);
            last_report_ns = now;
            gc_counter += 1;
            if gc_counter.is_multiple_of(5) { assembler.gc(now); }
        }

        if let Some(ref mut tun_file) = tun {
            // Only forward if session established
            if let NodeState::Established { ref cipher, .. } = state {
                // TX arrays pre-allocated outside loop — no per-tick memset.
                let mut tx_count_batch: usize = 0;

                // Phase 1: Batch TUN read — collect all frames before encrypting
                for _ in 0..TUN_BATCH {
                    let frame = &mut tx_bufs[tx_count_batch];
                    // Zero-copy TUN → tx_buf: read directly into payload region (offset 62)
                    match tun_file.read(&mut frame[62..1562]) {
                        Ok(n) if n > 0 => {
                            // Copy pre-built header template (static 46 bytes)
                            frame[0..46].copy_from_slice(&hdr_template[0..46]);
                            let frame_seq = seq_tx + tx_count_batch as u64;
                            frame[46..54].copy_from_slice(&frame_seq.to_le_bytes());
                            frame[54] = FLAG_TUNNEL;
                            frame[55..59].copy_from_slice(&(n as u32).to_le_bytes());
                            frame[59..62].copy_from_slice(&hdr_template[59..62]);

                            tx_lens[tx_count_batch] = 62 + n;
                            tun_read_count += 1;
                            tx_count_batch += 1;
                        }
                        _ => break, // WouldBlock or EOF — drain complete
                    }
                }

                // Phase 2: Vectorized AEAD encrypt — 4-at-a-time prefetch saturates AES-NI/ARMv8-CE
                // Then batch flush via sendmmsg — single syscall for all TUN packets
                if tx_count_batch > 0 {
                    let seq_base = seq_tx;
                    // Stack-allocated: zero heap allocation on hot path
                    let mut enc_ptrs: [*mut u8; TUN_BATCH] = [std::ptr::null_mut(); TUN_BATCH];
                    for i in 0..tx_count_batch {
                        enc_ptrs[i] = tx_bufs[i].as_mut_ptr();
                    }
                    crate::cryptography::aead::encrypt_batch_ptrs(
                        &enc_ptrs, &tx_lens, tx_count_batch,
                        cipher, DIR_NODE_TO_HUB, seq_base,
                    );
                    seq_tx += tx_count_batch as u64;

                    for i in 0..tx_count_batch {
                        tx_iovecs[i].iov_base = tx_bufs[i].as_mut_ptr() as *mut libc::c_void;
                        tx_iovecs[i].iov_len = tx_lens[i];
                        tx_msgs[i].msg_hdr.msg_iov = &mut tx_iovecs[i] as *mut libc::iovec;
                        tx_msgs[i].msg_hdr.msg_iovlen = 1;
                    }
                    // SAFETY: Caller ensures invariants documented at module level.
                    let sent = unsafe {
                        libc::sendmmsg(raw_fd, tx_msgs.as_mut_ptr(), tx_count_batch as u32, 0)
                    };
                    if sent > 0 { tx_count += sent as u64; }
                }
            }
        }
    }
    // Teardown routes on exit
    if routes_installed {
        teardown_tunnel_routes(&hub_ip);
    }
    eprintln!("[M13-N0] Shutdown. RX:{} TX:{} TUN_R:{} TUN_W:{} AEAD_OK:{} FAIL:{}",
        rx_count, tx_count, tun_read_count, tun_write_count, aead_ok_count, aead_fail_count);
}
